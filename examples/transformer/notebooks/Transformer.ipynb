{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ea85e1",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08985073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fitz\n",
    "# !pip install PyMuPdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bd84fb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PyMuPdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cd6792152dfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# import fitz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mPyMuPdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mftfy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PyMuPdf'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "import os, gc, re, psutil, traceback\n",
    "import timeit, datetime\n",
    "import pandas as pd\n",
    "import fitz\n",
    "import ftfy\n",
    "import nltk\n",
    "import warnings\n",
    "import pdfplumber, spacy\n",
    "import time, warnings, traceback, spacy\n",
    "import spacy\n",
    "import os, time, warnings, traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import dask.multiprocessing\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import pipeline\n",
    "from googletrans import Translator\n",
    "from collections import deque\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from etl.core.logger import WattleLogger\n",
    "from etl.core.concrete import WattleExtract, WattleTransform\n",
    "from etl.utils.base import WattleUtils\n",
    "from etl.core.constants import (\n",
    "    MSG_FILE_EXIST,\n",
    "    MSG_FILE_DOWNLOADED,\n",
    "    METHOD_EXEC,\n",
    "    MSG_CSV_FILE_ERROR,\n",
    "    MSG_FILE_CREATED,\n",
    "    MSG_NOT_FOUND\n",
    ")\n",
    "\n",
    "msg = lambda txt: f\"[{datetime.datetime.now()}]: {txt}\"\n",
    "def execution_time(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            start = timeit.default_timer()\n",
    "            result = func(*args, **kwargs)\n",
    "            end = timeit.default_timer()\n",
    "            m = psutil.virtual_memory()\n",
    "            print(f\"{msg(func.__name__)} \\\n",
    "took {end-start:.2f} sec | \\\n",
    "Memory | Used: {m.used / (1024 ** 3):.2f}GB \\\n",
    "({m.percent}%) | Available: \\\n",
    "{m.available/(1024 ** 3):.2f}GB of \\\n",
    "{m.total / (1024 ** 3):.3f}GB \\\n",
    "\")\n",
    "            return result\n",
    "        return wrapper\n",
    "print(msg(\"Done.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b3fcc72",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "<class '__main__.ExtractPaper'>._process_file: name 'fitz' is not defined\nTraceback (most recent call last):\n  File \"<ipython-input-7-ef0233b6dd1d>\", line 116, in process_file\n    pdf = fitz.open(filename);\nNameError: name 'fitz' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ef0233b6dd1d>\u001b[0m in \u001b[0;36mprocess_file\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 \u001b[0mpage_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_count\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fitz' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ef0233b6dd1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWattleLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logger\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtractPaper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extract\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;31m# tt = TranslatePaper(log, params['translate1']); del tt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;31m# tt = SummarisePaper(log, params['summarise']);  del tt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ef0233b6dd1d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, log, params)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_senteces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ef0233b6dd1d>\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ef0233b6dd1d>\u001b[0m in \u001b[0;36mprocess_file\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{self.__class__}._process_file: {e}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: <class '__main__.ExtractPaper'>._process_file: name 'fitz' is not defined\nTraceback (most recent call last):\n  File \"<ipython-input-7-ef0233b6dd1d>\", line 116, in process_file\n    pdf = fitz.open(filename);\nNameError: name 'fitz' is not defined\n"
     ]
    }
   ],
   "source": [
    "EXTRACTOR_MAX_WORDS  = 400\n",
    "EXTRACTOR_MAX_LENGTH = 2000\n",
    "SUMMARISER_MAX_WORDS = 500\n",
    "TRANSLATOR_MAX_WORDS = 400\n",
    "TRANSLATOR_SRC       = 'hr'\n",
    "TRANSLATOR_DEST      = 'en'\n",
    "DEFAULT_MULTIPLIER   = 0.7\n",
    "SUMMARY_TEXT         = 'summary_text'\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "coeficient = lambda w, m: int(w * m)\n",
    "inc     = lambda i: i + 1\n",
    "merge   = lambda c,l : f\"{c}\".join(l)\n",
    "length  = lambda l:  len(l) > 0\n",
    "zero    = lambda l:  len(l) == 0\n",
    "bigger  = lambda a,  b: len(a) > b if isinstance(a, list) else  a > b\n",
    "smaller = lambda a,  b: len(a) < b if isinstance(a, list) else  a < b\n",
    "cols    = lambda df, x: [el for el in df.columns if el.startswith(x)]\n",
    "# get      = lambda a,b,m,n l: [r for r in l if r[a] == m and r[b] == n]\n",
    "\n",
    "min_max_range = [\n",
    "    (  0,    20, 0.85, 0.31),\n",
    "    ( 20,    50, 0.75, 0.32),\n",
    "    ( 50,   100, 0.74, 0.33),\n",
    "    (100,   200, 0.73, 0.34),\n",
    "    (200,   300, 0.72, 0.35),\n",
    "    (300,   400, 0.71, 0.36),\n",
    "    (400,   500, 0.70, 0.37)\n",
    "]\n",
    "\n",
    "def min_max(x):\n",
    "    for n in min_max_range:\n",
    "        if x > n[0] and x < n[1]:\n",
    "            return int(x*n[2]), int(x*n[3])\n",
    "    return int(x * 0.75), int(x * 0.35)\n",
    "\n",
    "class Stats:\n",
    "    def __init__(self, filename):\n",
    "        self.pages = {}\n",
    "        self.filename = filename\n",
    "\n",
    "    def __str__(self):\n",
    "        p, r, w, c = 0,0,0,0\n",
    "        for pg in self.pages:\n",
    "            if pg != p: p += 1\n",
    "            r += int(self.pages[pg]['Paragraphs'])\n",
    "            w += int(self.pages[pg]['Words'])\n",
    "            c += int(self.pages[pg]['Characters'])\n",
    "        return f\"Stats: {p} pages, {r} paragraphs and {w} words, also with {c} characters. [{self.filename}]\"\n",
    "\n",
    "    def add(self, pg, text):\n",
    "        if pg in self.pages:\n",
    "            self.pages[pg]['Paragraphs'] += 1\n",
    "            self.pages[pg]['Words'] += len(text.split())\n",
    "            self.pages[pg]['Characters'] += len(text)\n",
    "        else:\n",
    "            self.pages[pg] = {'Page':pg, 'Paragraphs': 1, 'Words': len(text.split()), 'Characters': len(text)}\n",
    "\n",
    "class ExtractPaper(WattleExtract):\n",
    "    def __init__(self, log, params):\n",
    "        super().__init__(log, params)\n",
    "        assert isinstance(params['path'], str)\n",
    "        assert isinstance(params['ext'], str)\n",
    "\n",
    "        self.path = params['path']\n",
    "        self.ext = params['ext']\n",
    "        self.progress = None\n",
    "        self.filelist = deque()\n",
    "        self.statlist = deque()\n",
    "        self.buffer = deque()\n",
    "        self.counter = 0\n",
    "        self.pages = params['pages'] if 'pages' in params else None\n",
    "        self.max_words = params['max_words'] if 'max_words' in params else EXTRACTOR_MAX_WORDS\n",
    "        self.max_length = params['max_length'] if 'max_length' in params else EXTRACTOR_MAX_LENGTH\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.lines = deque()\n",
    "        self.extract()\n",
    "\n",
    "    def make_senteces(self, block, pg):\n",
    "        if 'lines' in block:\n",
    "            self.lines.clear()\n",
    "            self.counter += 1\n",
    "            for line in block['lines']:\n",
    "                txt = line['spans'][0]['text'].strip()\n",
    "                txt = re.sub(r'[^\\x00-\\x7F]+', '', txt)\n",
    "                self.lines.append(txt)\n",
    "\n",
    "        if len(self.lines) <=0: return\n",
    "        pg, words, length = inc(pg), 0,0\n",
    "        text = ' '.join(self.lines).strip()\n",
    "        self.stats.add(pg, text)\n",
    "        self.lines.clear()\n",
    "        sentences = [ f\"{s}\" for s in self.nlp(text).sents ]\n",
    "        for s in sentences:\n",
    "            words += len(s.split())\n",
    "            length += len(s)\n",
    "            if words < self.max_words and length < self.max_length:\n",
    "                self.lines.append(s)\n",
    "            else:\n",
    "                text = ' '.join(self.lines); self.lines.clear();\n",
    "                line = { 'text': text, 'pg': pg, 'block': self.counter, 'wc': len(text.split()), 'chars': len(text) }\n",
    "                self.buffer.append(line)\n",
    "                self.lines.append(s)\n",
    "                words += len(s.split())\n",
    "                length += len(s)\n",
    "\n",
    "        if len(self.lines) > 0:\n",
    "            line = { 'text': text, 'pg': pg, 'block': self.counter, 'wc': len(text.split()), 'chars': len(text) }\n",
    "            self.buffer.append(line)\n",
    "        self.lines.clear()\n",
    "\n",
    "    def process_file(self, filename):\n",
    "        try:\n",
    "            if filename.endswith('.pdf'):\n",
    "                pdf = fitz.open(filename);\n",
    "                page_range = range(pdf.page_count) if self.pages is None else self.pages\n",
    "                self.progress = tqdm(total=len(page_range), desc=f\"Extracting: [{filename}]\")\n",
    "                for page_num in page_range:\n",
    "                    page      = pdf[page_num]\n",
    "                    page_dict = page.get_text(\"dict\")\n",
    "                    for block in page_dict['blocks']:\n",
    "                        self.make_senteces(block, page_num)\n",
    "                    time.sleep(0.1)\n",
    "                    self.progress.update(1)\n",
    "                del pdf\n",
    "            df = pd.DataFrame(self.buffer)\n",
    "            file_name = filename.replace(\".pdf\", \".csv\")\n",
    "            df.to_csv(file_name, index=False)\n",
    "            del df\n",
    "        except Exception as e:\n",
    "            msg = f\"{self.__class__}._process_file: {e}\\n\"\n",
    "            msg += traceback.format_exc()\n",
    "            raise Exception(msg)\n",
    "        finally:\n",
    "            gc.collect()\n",
    "\n",
    "    def extract(self):\n",
    "        super().extract()\n",
    "        if not WattleUtils.path_exists(self.path):\n",
    "            msg = MSG_NOT_FOUND.format(\"File\", self.path)\n",
    "            self.log.error(msg)\n",
    "            raise FileNotFoundError(msg)\n",
    "\n",
    "        for name in os.listdir(self.path):\n",
    "            if name.endswith(self.ext):\n",
    "                filename = os.path.join(self.path, name)\n",
    "                self.filelist.append(filename)\n",
    "                self.stats = Stats(name)\n",
    "                self.process_file(name)\n",
    "                self.statlist.append(self.stats)\n",
    "                self.counter += 1\n",
    "                self.log.info(self.stats)\n",
    "\n",
    "        if zero(self.filelist):\n",
    "            msg=f\"WARNING: Files {self.ext} not found.\"\n",
    "            self.log.warning(msg)\n",
    "            raise Exception(msg)\n",
    "\n",
    "class SummarisePaper(WattleTransform):\n",
    "    def __init__(self, log, params):\n",
    "        super().__init__(log, params)\n",
    "        assert isinstance(params['path'], str)\n",
    "        assert isinstance(params['ext'], str)\n",
    "        assert isinstance(params['model'], str)\n",
    "        assert isinstance(params['from_column'], str)\n",
    "        assert isinstance(params['to_column'], str)\n",
    "        assert isinstance(params['num_threads'], int)\n",
    "        assert isinstance(params['min_threshold'], int)\n",
    "        self.path = params['path']\n",
    "        self.ext = params['ext']\n",
    "        self.filelist = deque()\n",
    "        self.statlist = deque()\n",
    "        self.buffer   = deque()\n",
    "        self.counter  = 0\n",
    "        self.model         = params['model'] #if 'model' in params else \"sshleifer/distilbart-cnn-12-6\"\n",
    "        self.from_column   = params['from_column']\n",
    "        self.to_column     = params['to_column']\n",
    "        self.num_threads   = int(params['num_threads'])\n",
    "        self.min_threshold = int(params['min_threshold'])\n",
    "        self.nlp           = spacy.load(\"en_core_web_sm\")\n",
    "        self.summariser    = pipeline(\"summarization\", model=self.model)\n",
    "        self.progress      = None\n",
    "        self.transform()\n",
    "\n",
    "    def transform(self):\n",
    "        super().transform()\n",
    "        if not WattleUtils.path_exists(self.path):\n",
    "            msg = MSG_NOT_FOUND.format(\"File\", self._input)\n",
    "            self.log.error(msg)\n",
    "            raise FileNotFoundError(msg)\n",
    "\n",
    "        for name in os.listdir(self.path):\n",
    "            if name.endswith(self.ext):\n",
    "                filename = os.path.join(self.path, name)\n",
    "                self.filelist.append(filename)\n",
    "                self.stats = Stats(name)\n",
    "                self.process_file(name)\n",
    "                self.statlist.append(self.stats)\n",
    "                self.counter += 1\n",
    "                self.log.info(self.stats)\n",
    "\n",
    "        if zero(self.filelist):\n",
    "            msg=f\"WARNING: Files {self.ext} not found.\"\n",
    "            self.log.warning(msg)\n",
    "            raise Exception(msg)\n",
    "\n",
    "    def _column_check(self, df):\n",
    "        if not self.from_column in df.columns:\n",
    "            raise Exception( f\"Column {self.from_column} doesn't exist in csv file.\" )\n",
    "\n",
    "        if self.to_column in df.columns:\n",
    "            if self.drop == True: df.drop(self.to_column, axis=1, inplace=True)\n",
    "\n",
    "    def _apply(self, text):\n",
    "        self.counter += 1\n",
    "        wc = len(f\"{text}\".split())\n",
    "        if not wc >= self.min_threshold:\n",
    "            self.stats.add(self.counter, text);\n",
    "            self.progress.update(1)\n",
    "            return ''\n",
    "\n",
    "        max, min = min_max(wc)\n",
    "        summary  = self.summariser(text, max_length=max, min_length=min, do_sample=False)[0][SUMMARY_TEXT]\n",
    "        self.stats.add(self.counter, summary);\n",
    "        self.progress.update(1)\n",
    "        return summary\n",
    "\n",
    "    def process_file(self, filename):\n",
    "        try:\n",
    "            df = pd.read_csv(filename)\n",
    "            self._column_check(df)\n",
    "            self.progress = tqdm(total=len(df), desc=f\"Summarisng: {filename}\")\n",
    "            with ThreadPoolExecutor(max_workers=self.num_threads) as executor:\n",
    "                column = list(executor.map(self._apply, df[self.from_column]))\n",
    "            df.insert(0, self.to_column, column)\n",
    "            df.to_csv(filename, index=False)\n",
    "            del df\n",
    "        except Exception as e:\n",
    "            msg = f\"{self.__class__}._process_file: {e}\\n\"\n",
    "            msg += traceback.format_exc()\n",
    "            raise Exception(msg)\n",
    "        finally:\n",
    "            gc.collect()\n",
    "\n",
    "class TranslatePaper(WattleTransform):\n",
    "    def __init__(self, log, params):\n",
    "        super().__init__(log, params)\n",
    "        assert isinstance(params['path'], str)\n",
    "        assert isinstance(params['ext'], str)\n",
    "        assert isinstance(params['from_column'], str)\n",
    "        assert isinstance(params['to_column'], str)\n",
    "        assert isinstance(params['src'], str)\n",
    "        assert isinstance(params['dest'], str)\n",
    "        assert isinstance(params['min_threshold'], int)\n",
    "        assert isinstance(params['num_threads'], int)\n",
    "        self.path = params['path']\n",
    "        self.ext = params['ext']\n",
    "        self.from_column = params['from_column']\n",
    "        self.to_column = params['to_column']\n",
    "        self.src = params['src']\n",
    "        self.dest = params['dest']\n",
    "        self.drop = params['drop'] if 'drop' in params else None\n",
    "        self.min_threshold = params['min_threshold']\n",
    "        self.num_threads = params['num_threads']\n",
    "        self.progress = None\n",
    "        self.filelist = deque()\n",
    "        self.statlist = deque()\n",
    "        self.buffer = deque()\n",
    "        self.counter = 0\n",
    "        self.transform()\n",
    "\n",
    "    def _apply(self, text):\n",
    "        self.counter += 1;\n",
    "        wc = len(f\"{text}\".split())\n",
    "        if not wc >= self.min_threshold:\n",
    "            self.stats.add(self.counter, '')\n",
    "            self.progress.update(1)\n",
    "            return ''\n",
    "        translator = Translator()\n",
    "        translated = translator.translate(text, src=self.src, dest=self.dest).text\n",
    "        self.stats.add(self.counter, translated)\n",
    "        self.progress.update(1)\n",
    "        return translated\n",
    "\n",
    "    def _column_check(self, df):\n",
    "        if not self.from_column in df.columns:\n",
    "            raise Exception( f\"Column {self.from_column} doesn't exist in csv file.\" )\n",
    "\n",
    "        if self.to_column in df.columns:\n",
    "            if self.drop == True: df.drop(self.to_column, axis=1, inplace=True)\n",
    "\n",
    "    def process_file(self, filename):\n",
    "        try:\n",
    "            df = pd.read_csv(filename)\n",
    "            self._column_check(df)\n",
    "            self.progress = tqdm(total=len(df), desc=f\"Translating: {filename}\")\n",
    "            num_threads = self.num_threads\n",
    "            with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "                column = list(executor.map(self._apply, df[self.from_column]))\n",
    "            df.insert(0, self.to_column, column)\n",
    "            df.to_csv(filename, index=False)\n",
    "            del df\n",
    "        except Exception as e:\n",
    "            msg = f\"{self.__class__}._process_file: {e}\\n\"\n",
    "            # msg += traceback.format_exc()\n",
    "            self.log.error(msg)\n",
    "            raise Exception(msg)\n",
    "        finally:\n",
    "            gc.collect()\n",
    "\n",
    "    def transform(self):\n",
    "        super().transform()\n",
    "        if not WattleUtils.path_exists(self.path):\n",
    "            msg = MSG_NOT_FOUND.format(\"File\", self._input)\n",
    "            self.log.error(msg)\n",
    "            raise FileNotFoundError(msg)\n",
    "\n",
    "        for name in os.listdir(self.path):\n",
    "            if name.endswith(self.ext):\n",
    "                filename = os.path.join(self.path, name)\n",
    "                self.filelist.append(filename)\n",
    "                self.stats = Stats(name)\n",
    "                self.process_file(name)\n",
    "                self.statlist.append(self.stats)\n",
    "                self.counter += 1\n",
    "                self.log.info(self.stats)\n",
    "\n",
    "        if zero(self.filelist):\n",
    "            msg=f\"WARNING: Files {self.ext} not found.\"\n",
    "            self.log.warning(msg)\n",
    "            raise Exception(msg)\n",
    "params_str = \"\"\"\n",
    "logger:\n",
    "    name: etl.log\n",
    "    level: ERROR\n",
    "extract:\n",
    "    path: ../data\n",
    "    ext: .pdf\n",
    "    max_words: 400\n",
    "    max_length: 2000\n",
    "translate1:\n",
    "    path: ../data\n",
    "    ext: .csv\n",
    "    from_column: text\n",
    "    to_column: text-hr\n",
    "    src: en\n",
    "    dest: hr\n",
    "    min_threshold: 2\n",
    "    num_threads: 100\n",
    "summarise:\n",
    "    path: ../data\n",
    "    ext: \".csv\"\n",
    "    model1: \"sshleifer/distilbart-cnn-12-6\"\n",
    "    model2: \"google/pegasus-xsum\"\n",
    "    model: \"facebook/bart-large-cnn\"\n",
    "    from_column: text\n",
    "    to_column: summary-en\n",
    "    min_threshold: 50\n",
    "    num_threads: 50\n",
    "    drop: True\n",
    "translate2:\n",
    "    path: ../data\n",
    "    ext: .csv\n",
    "    from_column: summary-en\n",
    "    to_column: summary-hr\n",
    "    src: en\n",
    "    dest: hr\n",
    "    min_threshold: 50\n",
    "    num_threads: 100\n",
    "    drop: True\n",
    "\"\"\"\n",
    "import yaml\n",
    "params = yaml.safe_load(params_str)\n",
    "log = WattleLogger(params[\"logger\"])\n",
    "tt = ExtractPaper(log, params[\"extract\"]); del tt\n",
    "# tt = TranslatePaper(log, params['translate1']); del tt\n",
    "# tt = SummarisePaper(log, params['summarise']);  del tt\n",
    "# tt = TranslatePaper(log, params['translate2']); del tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23904275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping PyMuPdf as it is not installed.\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting PyMuPdf\n",
      "  Downloading PyMuPDF-1.19.6.tar.gz (2.3 MB)\n",
      "     |################################| 2.3 MB 1.0 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: PyMuPdf\n",
      "  Building wheel for PyMuPdf (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-6zc1_42u/pymupdf_6e42cad86ea74e39b4c821d2f205de53/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-6zc1_42u/pymupdf_6e42cad86ea74e39b4c821d2f205de53/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-lnru1j5h\n",
      "       cwd: /tmp/pip-install-6zc1_42u/pymupdf_6e42cad86ea74e39b4c821d2f205de53/\n",
      "  Complete output (20 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-3.6\n",
      "  creating build/lib.linux-x86_64-3.6/fitz\n",
      "  copying fitz/__init__.py -> build/lib.linux-x86_64-3.6/fitz\n",
      "  copying fitz/fitz.py -> build/lib.linux-x86_64-3.6/fitz\n",
      "  copying fitz/utils.py -> build/lib.linux-x86_64-3.6/fitz\n",
      "  copying fitz/__main__.py -> build/lib.linux-x86_64-3.6/fitz\n",
      "  running build_ext\n",
      "  building 'fitz._fitz' extension\n",
      "  creating build/temp.linux-x86_64-3.6\n",
      "  creating build/temp.linux-x86_64-3.6/fitz\n",
      "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/mupdf -I/usr/local/include/mupdf -Imupdf/thirdparty/freetype/include -I/usr/include/freetype2 -I/usr/include/python3.6m -c fitz/fitz_wrap.c -o build/temp.linux-x86_64-3.6/fitz/fitz_wrap.o\n",
      "  fitz/fitz_wrap.c:2755:10: fatal error: fitz.h: No such file or directory\n",
      "   #include <fitz.h>\n",
      "            ^~~~~~~~\n",
      "  compilation terminated.\n",
      "  error: command 'x86_64-linux-gnu-gcc' failed with exit status 1\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for PyMuPdf\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for PyMuPdf\n",
      "Failed to build PyMuPdf\n",
      "Installing collected packages: PyMuPdf\n",
      "    Running setup.py install for PyMuPdf ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-6zc1_42u/pymupdf_6e42cad86ea74e39b4c821d2f205de53/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-6zc1_42u/pymupdf_6e42cad86ea74e39b4c821d2f205de53/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-_6mnpr1c/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.6/PyMuPdf\n",
      "         cwd: /tmp/pip-install-6zc1_42u/pymupdf_6e42cad86ea74e39b4c821d2f205de53/\n",
      "    Complete output (22 lines):\n",
      "    running install\n",
      "    /usr/local/lib/python3.6/dist-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "      setuptools.SetuptoolsDeprecationWarning,\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.6\n",
      "    creating build/lib.linux-x86_64-3.6/fitz\n",
      "    copying fitz/__init__.py -> build/lib.linux-x86_64-3.6/fitz\n",
      "    copying fitz/fitz.py -> build/lib.linux-x86_64-3.6/fitz\n",
      "    copying fitz/utils.py -> build/lib.linux-x86_64-3.6/fitz\n",
      "    copying fitz/__main__.py -> build/lib.linux-x86_64-3.6/fitz\n",
      "    running build_ext\n",
      "    building 'fitz._fitz' extension\n",
      "    creating build/temp.linux-x86_64-3.6\n",
      "    creating build/temp.linux-x86_64-3.6/fitz\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/mupdf -I/usr/local/include/mupdf -Imupdf/thirdparty/freetype/include -I/usr/include/freetype2 -I/usr/include/python3.6m -c fitz/fitz_wrap.c -o build/temp.linux-x86_64-3.6/fitz/fitz_wrap.o\n",
      "    fitz/fitz_wrap.c:2755:10: fatal error: fitz.h: No such file or directory\n",
      "     #include <fitz.h>\n",
      "              ^~~~~~~~\n",
      "    compilation terminated.\n",
      "    error: command 'x86_64-linux-gnu-gcc' failed with exit status 1\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-6zc1_42u/pymupdf_6e42cad86ea74e39b4c821d2f205de53/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-6zc1_42u/pymupdf_6e42cad86ea74e39b4c821d2f205de53/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-_6mnpr1c/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.6/PyMuPdf Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!python3 -m pip uninstall PyMuPdf\n",
    "!python3 -m pip install --no-cache-dir PyMuPdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f9e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
